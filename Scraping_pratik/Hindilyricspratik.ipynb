{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make it run on py2 and py3\n",
    "from __future__ import division, print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests # The requests library is an \n",
    "# HTTP library for getting and posting content etc.\n",
    "\n",
    "import bs4 as bs # BeautifulSoup4 is a Python library \n",
    "# for pulling data out of HTML and XML code.\n",
    "# We can query markup languages for specific content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = requests.get('https://hindilyricspratik.blogspot.com/search?max-results=500').content \n",
    "# get the source content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = bs.BeautifulSoup(source,'html.parser')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(soup.prettify()) \n",
    "# .prettify() method makes the HTML code more readable\n",
    "\n",
    "# as you can see this code is more difficult \n",
    "# to read then the simple example above\n",
    "# mostly because this is a real Wordpress website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the csv file in write mode and adding a header\n",
    "with open(r'hindilyricspratik_phase1.csv', 'w') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Song Devanagiri\", \"Song Roman\",\"Movie\",\"Year\",\"Music Director\",\"Lyricist\",\"Singers\",\"Lyrics\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "#navigation_bar = soup.find_all(class_='post-body entry-content')\n",
    "#print(navigation_bar.text)\n",
    "count = 0 #count of number of songs scraped per page\n",
    "listofsongs=[]\n",
    "count_out=0 #counter for the outer loop where soup is expected to get updated based on the URL of the \"Older Page\"\n",
    "\n",
    "try:\n",
    "    while soup.find_all(class_='blog-pager-older-link') != []: #idea for while: Loop runs till no option for 'Older Page' to show up\n",
    "        for url in soup.find_all(class_='blog-pager-older-link'):\n",
    "            source_updated=url.get('href') #just stores the URL of the page that will open on clicking \"Older Next\"\n",
    "            #print(source_updated)\n",
    "            for song in soup.find_all(class_=\"post hentry\"): #this is still in the current page\n",
    "                song_title=(song.find('h3',class_=\"post-title entry-title\").text).split(\" (\")[0]\n",
    "                song_title_temp=song_title.split(\" -\")\n",
    "                song_title_deva=song_title_temp[0]\n",
    "                song_title_roman=song_title_temp[-1].split(\" (\")[0]\n",
    "                song_lyrics=song.find('div',class_='post-body entry-content').div.text\n",
    "                lyrics=\"\\n\\n\".join(song_lyrics.split('\\n\\n')[1:])\n",
    "                lyrics=lyrics.replace(\", \",\"\\n\")\n",
    "\n",
    "                aboutlyrics=song_lyrics.split('\\n\\n')[0]\n",
    "                info_song_list=aboutlyrics.split('\\n')\n",
    "\n",
    "                for i in range(1,len(info_song_list)):\n",
    "                    info_song=info_song_list[i].split(\": \")[-1]\n",
    "\n",
    "                    if i==1:\n",
    "                        movie_year=info_song.split(\" (\")\n",
    "                        movie=movie_year[0]\n",
    "                        year=movie_year[-1][0:4]\n",
    "                        print(movie)\n",
    "                        print(year)\n",
    "                    elif i==2:\n",
    "                        music_director=info_song\n",
    "                        print(music_director)\n",
    "                    elif i==3:\n",
    "                        lyricist=info_song\n",
    "                        print(lyricist)\n",
    "                    elif i==4:\n",
    "                        singer=info_song\n",
    "                        print(singer)\n",
    "                listofsongs.append([song_title_deva,song_title_roman,movie,year,music_director,lyricist,singer,lyrics])\n",
    "\n",
    "                print(\"\\n\")\n",
    "                print(lyrics+\"\\n\")\n",
    "                count+=1\n",
    "            \n",
    "            soup = bs.BeautifulSoup(source_updated,'html.parser')\n",
    "            #print(soup)\n",
    "\n",
    "            #count+=1\n",
    "        #print(listofsongs)\n",
    "        print(\"-----------------------------------\",count)\n",
    "        print(\"\\nOuter loop iteration:\",count_out)\n",
    "        print(\"--------------------------------------------\")\n",
    "        count_out+=1\n",
    "    \n",
    "        #break \n",
    "    with open(r'hindilyricspratik_phase1.csv', 'a') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerows(listofsongs) \n",
    "        \n",
    "    \n",
    "\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(r'lyricsia_phase1.csv', 'a') as file:\n",
    "#             writer = csv.writer(file)\n",
    "#             writer.writerows(listofsongs)    \n",
    "            \n",
    "# except Exception as e:\n",
    "#     print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "        #listofsongs.append([song_title, songurl, moviename])\n",
    "#print('-----------------')\n",
    "\n",
    "# Opening the file in append mode and adding the data for the entire page i.e. each year\n",
    "#     with open(r'lyricsia_phase1.csv', 'a') as file:\n",
    "#         writer = csv.writer(file)\n",
    "#         writer.writerows(listofsongs)\n",
    "            \n",
    "#         # Printing the progress\n",
    "#         print(f'Data Scraped for song: {year}')\n",
    "# except Exception as e:\n",
    "#     print(e)\n",
    "\n",
    "#     print(count)\n",
    "\n",
    "\n",
    "#count = 0\n",
    "#for url in soup.find_all(class_='post-body entry-content'): \n",
    "#     link = url.text\n",
    "#     count+=1\n",
    "#     print(link)\n",
    "# print(count)\n",
    "\n",
    "# hello=lis[77].ul\n",
    "# print(hello)\n",
    "\n",
    "#tiltles = soup.find_all(class_='post-title entry-title') \n",
    "#print(titles.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://hindilyricspratik.blogspot.com/search?updated-max=2019-08-27T12:43:00%2B05:30&max-results=200&start=97&by-date=false\n"
     ]
    }
   ],
   "source": [
    "for url in soup.find_all(class_='blog-pager-older-link'):\n",
    "    link = url.get('href')\n",
    "    print(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
